import os
import imp
import tensorflow as tf
import math
import numpy as np
import itertools
import matplotlib.pyplot as plt
m = imp.find_module('waymo_open_dataset', ['.'])
imp.load_module('waymo_open_dataset', m[0], m[1], m[2])
from waymo_open_dataset.utils import range_image_utils
from waymo_open_dataset.utils import transform_utils
from waymo_open_dataset import dataset_pb2 as open_dataset
import tensorflow.compat.v1 as tf



def image_show(data, name, layout, cmap=None):
    """Show an image."""
    plt.subplot(*layout)
    plt.imshow(tf.image.decode_jpeg(data), cmap=cmap)
    plt.title(name)
    plt.grid(False)
    plt.axis('off')





def parse_range_image_and_camera_projection(frame):
    """Parse range images and camera projections given a frame.

    Args:
       frame: open dataset frame proto
    Returns:
       range_images: A dict of {laser_name,
         [range_image_first_return, range_image_second_return]}.
       camera_projections: A dict of {laser_name,
         [camera_projection_from_first_return,
          camera_projection_from_second_return]}.
      range_image_top_pose: range image pixel pose for top lidar.
    """
    range_images = {}
    camera_projections = {}
    range_image_top_pose = None
    for laser in frame.lasers:
        if len(laser.ri_return1.range_image_compressed) > 0:
            # use tf.io.decode_compressed() if TF 2.0
            range_image_str_tensor = tf.decode_compressed(
                laser.ri_return1.range_image_compressed, 'ZLIB')
            ri = open_dataset.MatrixFloat()
            ri.ParseFromString(bytearray(range_image_str_tensor.numpy()))
            range_images[laser.name] = [ri]

            if laser.name == open_dataset.LaserName.TOP:
                # use tf.io.decode_compressed() if TF 2.0
                range_image_top_pose_str_tensor = tf.decode_compressed(
                    laser.ri_return1.range_image_pose_compressed, 'ZLIB')
                range_image_top_pose = open_dataset.MatrixFloat()
                range_image_top_pose.ParseFromString(
                    bytearray(range_image_top_pose_str_tensor.numpy()))

            # use tf.io.decode_compressed() if TF 2.0
            camera_projection_str_tensor = tf.decode_compressed(
                laser.ri_return1.camera_projection_compressed, 'ZLIB')
            cp = open_dataset.MatrixInt32()
            cp.ParseFromString(bytearray(camera_projection_str_tensor.numpy()))
            camera_projections[laser.name] = [cp]
        if len(laser.ri_return2.range_image_compressed) > 0:
            # use tf.io.decode_compressed() if TF 2.0
            range_image_str_tensor = tf.decode_compressed(
                laser.ri_return2.range_image_compressed, 'ZLIB')
            ri = open_dataset.MatrixFloat()
            ri.ParseFromString(bytearray(range_image_str_tensor.numpy()))
            range_images[laser.name].append(ri)

            # use tf.io.decode_compressed() if TF 2.0
            camera_projection_str_tensor = tf.decode_compressed(
                laser.ri_return2.camera_projection_compressed, 'ZLIB')
            cp = open_dataset.MatrixInt32()
            cp.ParseFromString(bytearray(camera_projection_str_tensor.numpy()))
            camera_projections[laser.name].append(cp)
    return range_images, camera_projections, range_image_top_pose




def plot_range_image_helper(data, name, layout, vmin=0, vmax=1, cmap='gray'):
    """Plots range image.
    Args:
      data: range image data
      name: the image title
      layout: plt layout
      vmin: minimum value of the passed data
      vmax: maximum value of the passed data
      cmap: color map
    """
    plt.subplot(*layout)
    plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)
    plt.title(name)
    plt.grid(False)
    plt.axis('off')


def get_range_image(laser_name, return_index):
    """Returns range image given a laser name and its return index."""
    return range_images[laser_name][return_index]


def show_range_image(range_image, layout_index_start=1):
    """Shows range image.

    Args:
      range_image: the range image data from a given lidar of type MatrixFloat.
      layout_index_start: layout offset
    """
    range_image_tensor = tf.convert_to_tensor(range_image.data)
    range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)
    lidar_image_mask = tf.greater_equal(range_image_tensor, 0)
    range_image_tensor = tf.where(lidar_image_mask, range_image_tensor,
                                  tf.ones_like(range_image_tensor) * 1e10)
    range_image_range = range_image_tensor[..., 0]
    range_image_intensity = range_image_tensor[..., 1]
    range_image_elongation = range_image_tensor[..., 2]
    plot_range_image_helper(range_image_range.numpy(), 'range',
                            [8, 1, layout_index_start], vmax=75, cmap='gray')
    plot_range_image_helper(range_image_intensity.numpy(), 'intensity',
                            [8, 1, layout_index_start + 1], vmax=1.5, cmap='gray')
    plot_range_image_helper(range_image_elongation.numpy(), 'elongation',
                            [8, 1, layout_index_start + 2], vmax=1.5, cmap='gray')



def convert_range_image_to_point_cloud(frame,
                                       range_images,
                                       camera_projections,
                                       range_image_top_pose,
                                       ri_index=0):
    """Convert range images to point cloud.

    Args:
      frame: open dataset frame
       range_images: A dict of {laser_name,
         [range_image_first_return, range_image_second_return]}.
       camera_projections: A dict of {laser_name,
         [camera_projection_from_first_return,
          camera_projection_from_second_return]}.
      range_image_top_pose: range image pixel pose for top lidar.
      ri_index: 0 for the first return, 1 for the second return.
    Returns:
      points: {[N, 3]} list of 3d lidar points of length 5 (number of lidars).
      cp_points: {[N, 6]} list of camera projections of length 5
        (number of lidars).
    """
    calibrations = sorted(frame.context.laser_calibrations, key=lambda c: c.name)
    lasers = sorted(frame.lasers, key=lambda laser: laser.name)
    points = []
    cp_points = []

    frame_pose = tf.convert_to_tensor(
        np.reshape(np.array(frame.pose.transform), [4, 4]))
    # [H, W, 6]
    range_image_top_pose_tensor = tf.reshape(
        tf.convert_to_tensor(range_image_top_pose.data),
        range_image_top_pose.shape.dims)
    # [H, W, 3, 3]
    range_image_top_pose_tensor_rotation = transform_utils.get_rotation_matrix(
        range_image_top_pose_tensor[..., 0], range_image_top_pose_tensor[..., 1],
        range_image_top_pose_tensor[..., 2])
    range_image_top_pose_tensor_translation = range_image_top_pose_tensor[..., 3:]
    range_image_top_pose_tensor = transform_utils.get_transform(
        range_image_top_pose_tensor_rotation,
        range_image_top_pose_tensor_translation)
    for c in calibrations:
        range_image = range_images[c.name][ri_index]
        if len(c.beam_inclinations) == 0:
            beam_inclinations = range_image_utils.compute_inclination(
                tf.constant([c.beam_inclination_min, c.beam_inclination_max]),
                height=range_image.shape.dims[0])
        else:
            beam_inclinations = tf.constant(c.beam_inclinations)

        beam_inclinations = tf.reverse(beam_inclinations, axis=[-1])
        extrinsic = np.reshape(np.array(c.extrinsic.transform), [4, 4])

        range_image_tensor = tf.reshape(
            tf.convert_to_tensor(range_image.data), range_image.shape.dims)
        pixel_pose_local = None
        frame_pose_local = None
        if c.name == open_dataset.LaserName.TOP:
            pixel_pose_local = range_image_top_pose_tensor
            pixel_pose_local = tf.expand_dims(pixel_pose_local, axis=0)
            frame_pose_local = tf.expand_dims(frame_pose, axis=0)
        range_image_mask = range_image_tensor[..., 0] > 0
        range_image_cartesian = range_image_utils.extract_point_cloud_from_range_image(
            tf.expand_dims(range_image_tensor[..., 0], axis=0),
            tf.expand_dims(extrinsic, axis=0),
            tf.expand_dims(tf.convert_to_tensor(beam_inclinations), axis=0),
            pixel_pose=pixel_pose_local,
            frame_pose=frame_pose_local)
        # range_image_intensity_cartesian = range_image_utils.extract_point_cloud_from_range_image(
        #     tf.expand_dims(range_image_tensor[..., 1], axis=0),
        #     tf.expand_dims(extrinsic, axis=0),
        #     tf.expand_dims(tf.convert_to_tensor(beam_inclinations), axis=0),
        #     pixel_pose = pixel_pose_local,
        #     frame_pose = frame_pose_local)

        range_image_cartesian = tf.squeeze(range_image_cartesian, axis=0)

        points_tensor = tf.gather_nd(range_image_cartesian,
                                     tf.where(range_image_mask))

        range_image_intensity_tensor = range_image_tensor[..., 1:2]
        points_intensity_tensor = tf.gather_nd(range_image_intensity_tensor,
                                     tf.where(range_image_mask))

        # range_image_intensity_cartesian = tf.squeeze(range_image_intensity_cartesian, axis=0)
        # points_intensity_tensor = tf.gather_nd(range_image_intensity_cartesian,
        #                                        tf.where(range_image_mask))

        cp = camera_projections[c.name][0]
        cp_tensor = tf.reshape(tf.convert_to_tensor(cp.data), cp.shape.dims)
        cp_points_tensor = tf.gather_nd(cp_tensor, tf.where(range_image_mask))
        points.append(np.concatenate([points_tensor.numpy(),points_intensity_tensor.numpy()],axis=1))
        # points.append(points_tensor.numpy())
        cp_points.append(cp_points_tensor.numpy())

    return points, cp_points





def rgba(r):
    """Generates a color based on range.

    Args:
      r: the range value of a given point.
    Returns:
      The color for a given range
    """
    c = plt.get_cmap('jet')((r % 20.0) / 20.0)
    c = list(c)
    c[-1] = 0.5  # alpha
    return c


def plot_image(camera_image):
    """Plot a cmaera image."""
    plt.figure(figsize=(20, 12))
    plt.imshow(tf.image.decode_jpeg(camera_image.image))
    plt.grid("off")


def plot_points_on_image(projected_points, camera_image, rgba_func,
                         point_size=5.0):
    """Plots points on a camera image.

    Args:
      projected_points: [N, 3] numpy array. The inner dims are
        [camera_x, camera_y, range].
      camera_image: jpeg encoded camera image.
      rgba_func: a function that generates a color from a range value.
      point_size: the point size.

    """
    plot_image(camera_image)

    xs = []
    ys = []
    colors = []

    for point in projected_points:
        xs.append(point[0])  # width, col
        ys.append(point[1])  # height, row
        colors.append(rgba_func(point[2]))
    plt.scatter(xs, ys, c=colors, s=point_size, edgecolors="none")


if __name__ == '__main__':
    tf.disable_v2_behavior()
    tf.enable_eager_execution()
    # read one frame
    # TODO: 1.修改为你要读取的record文件路径
    filepath = 'C:/Users/lenovo/Desktop/kitti-3d-visual/data/Waymo/segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord'
    FILENAME = filepath

    dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')

    frame_index = 0
    # TODO: 2.修改为你要读取的帧数，0-199
    target_index = 199
    for data in dataset:
        frame = open_dataset.Frame()
        frame.ParseFromString(bytearray(data.numpy()))

        if frame_index == target_index:
            break
        else:
            frame_index = frame_index + 1
    # for data in dataset:
    #     frame = open_dataset.Frame()
    #     frame.ParseFromString(bytearray(data.numpy()))
    #     # for index, image in enumerate(frame.images):
    #     #   image_show(image.image, open_dataset.CameraName.Name.Name(image.name), [3, 3, index+1])
    #     # plt.show()
    #     break

    (range_images, camera_projections, range_image_top_pose) = parse_range_image_and_camera_projection(frame)

    print(frame.context)

    # visualize the frame photo

    plt.figure(figsize=(25, 20))

    for index, image in enumerate(frame.images):
        image_show(image.image, open_dataset.CameraName.Name.Name(image.name), [3, 3, index + 1])
    # plt.show()

    # visualize the range info

    plt.figure(figsize=(64, 20))

    frame.lasers.sort(key=lambda laser: laser.name)
    show_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)
    # plt.show()

    show_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)

    # plt.show()

    points, cp_points = convert_range_image_to_point_cloud(frame,
                                                           range_images,
                                                           camera_projections,
                                                           range_image_top_pose)
    points_ri2, cp_points_ri2 = convert_range_image_to_point_cloud(
        frame,
        range_images,
        camera_projections,
        range_image_top_pose,
        ri_index=1)

    # 3d points in vehicle frame.
    points_all = np.concatenate(points, axis=0)
    points_all_ri2 = np.concatenate(points_ri2, axis=0)
    # camera projection corresponding to each point.
    cp_points_all = np.concatenate(cp_points, axis=0)
    cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)

    # examine point cloud
    print(points_all.shape)
    print(cp_points_all.shape)
    print(points_all[0:2])
    for i in range(5):
        print(points[i].shape)
        print(cp_points[i].shape)

    print(points_all_ri2.shape)
    print(cp_points_all_ri2.shape)
    print(points_all_ri2[0:2])
    for i in range(5):
        print(points_ri2[i].shape)
        print(cp_points_ri2[i].shape)

    # from IPython.display import Image, display
    # import cv2
    # display(Image('tutorial/3d_point_cloud.png'))
    # cv2.imshow('tutorial/3d_point_cloud.png')
    # visualize camera projection

    images = sorted(frame.images, key=lambda i: i.name)
    cp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)
    cp_points_all_concat_tensor = tf.constant(cp_points_all_concat)

    # The distance between lidar points and vehicle frame origin.
    points_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)
    cp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)

    mask = tf.equal(cp_points_all_tensor[..., 0], images[0].name)

    cp_points_all_tensor = tf.cast(tf.gather_nd(
        cp_points_all_tensor, tf.where(mask)), dtype=tf.float32)
    points_all_tensor = tf.gather_nd(points_all_tensor, tf.where(mask))

    projected_points_all_from_raw_data = tf.concat(
        [cp_points_all_tensor[..., 1:3], points_all_tensor], axis=-1).numpy()
    # TODO 3. 融合图像标号0-4

    mix_num = 0
    plot_points_on_image(projected_points_all_from_raw_data,
                         images[mix_num], rgba, point_size=5.0)

    plt.show()

